{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras import optimizers\n",
    "from keras import applications\n",
    "from keras.utils.np_utils import to_categorical \n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions of our images.\n",
    "img_width, img_height = 240, 240\n",
    "\n",
    "# n_classes = 6451\n",
    "# train_data_dir = 'data/train'\n",
    "# valid_data_dir = 'data/valid'\n",
    "n_classes = 46\n",
    "train_data_dir = 'data/train_sample'\n",
    "valid_data_dir = 'data/valid_sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "# train_samples = 859486\n",
    "# valid_samples = 294058\n",
    "train_samples = 4911\n",
    "valid_samples = 1690"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_datagen = ImageDataGenerator(\n",
    "#         rescale=1. / 255,      # Normalize pixel values to [0,1]\n",
    "#         shear_range=0.2,       # Randomly applies shearing transformation\n",
    "#         zoom_range=0.2,        # Randomly applies shearing transformation\n",
    "#         horizontal_flip=True)  # Randomly flip the images\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4911 images belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#         train_data_dir,\n",
    "#         target_size=(img_width, img_height),\n",
    "#         batch_size=batch_size)\n",
    "\n",
    "train_generator_bottleneck = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1690 images belonging to 46 classes.\n"
     ]
    }
   ],
   "source": [
    "# valid_generator = datagen.flow_from_directory(\n",
    "#         valid_data_dir,\n",
    "#         target_size=(img_width, img_height),\n",
    "#         batch_size=batch_size)\n",
    "\n",
    "valid_generator_bottleneck = datagen.flow_from_directory(\n",
    "        valid_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading VGG 16 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = applications.VGG16(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_train = model_vgg.predict_generator(train_generator_bottleneck)\n",
    "np.save(open('models/bottleneck_features_train.npy', 'wb'), bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_validation = model_vgg.predict_generator(valid_generator_bottleneck)\n",
    "np.save(open('models/bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_generator_bottleneck.class_indices)\n",
    "\n",
    "train_data = np.load(open('models/bottleneck_features_train.npy', 'rb'))\n",
    "train_labels = to_categorical(train_generator_bottleneck.classes[:train_samples], num_classes=num_classes)\n",
    "\n",
    "validation_data = np.load(open('models/bottleneck_features_validation.npy', 'rb'))\n",
    "validation_labels = to_categorical(valid_generator_bottleneck.classes[:valid_samples], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4911, 7, 7, 512)\n",
      "(4911, 46)\n",
      "(1690, 7, 7, 512)\n",
      "(1690, 46)\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "print train_data.shape\n",
    "print train_labels.shape\n",
    "print validation_data.shape\n",
    "print validation_labels.shape\n",
    "print len(train_generator_bottleneck.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_top = Sequential()\n",
    "model_top.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model_top.add(Dense(512, activation='relu'))\n",
    "model_top.add(Dropout(0.5))\n",
    "model_top.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_top.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Convolution2D(32, (3, 3), input_shape=(img_width, img_height, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Convolution2D(32, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Convolution2D(64, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(n_classes))\n",
    "# model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4911 samples, validate on 1690 samples\n",
      "Epoch 1/100\n",
      " - 6s - loss: 3.5072 - acc: 0.5266 - val_loss: 1.4123 - val_acc: 0.6686\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.66864, saving model to models/bottleneck_features.h5\n",
      "Epoch 2/100\n",
      " - 5s - loss: 1.2063 - acc: 0.7076 - val_loss: 0.9131 - val_acc: 0.7734\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.66864 to 0.77337, saving model to models/bottleneck_features.h5\n",
      "Epoch 3/100\n",
      " - 5s - loss: 0.8789 - acc: 0.7772 - val_loss: 0.7612 - val_acc: 0.8065\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.77337 to 0.80651, saving model to models/bottleneck_features.h5\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.7037 - acc: 0.8169 - val_loss: 0.9024 - val_acc: 0.8006\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.80651\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.5623 - acc: 0.8454 - val_loss: 0.7099 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.80651 to 0.84911, saving model to models/bottleneck_features.h5\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.4854 - acc: 0.8733 - val_loss: 0.5850 - val_acc: 0.8757\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.84911 to 0.87574, saving model to models/bottleneck_features.h5\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.4146 - acc: 0.8890 - val_loss: 0.7394 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.87574\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.3625 - acc: 0.9029 - val_loss: 0.5640 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.87574\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.3335 - acc: 0.9106 - val_loss: 0.6377 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.87574 to 0.87633, saving model to models/bottleneck_features.h5\n",
      "Epoch 10/100\n",
      " - 5s - loss: 0.2644 - acc: 0.9269 - val_loss: 0.6303 - val_acc: 0.8793\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.87633 to 0.87929, saving model to models/bottleneck_features.h5\n",
      "Epoch 11/100\n",
      " - 5s - loss: 0.2855 - acc: 0.9251 - val_loss: 0.6140 - val_acc: 0.8888\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.87929 to 0.88876, saving model to models/bottleneck_features.h5\n",
      "Epoch 12/100\n",
      " - 5s - loss: 0.2541 - acc: 0.9373 - val_loss: 0.6590 - val_acc: 0.8817\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.88876\n",
      "Epoch 13/100\n",
      " - 5s - loss: 0.2309 - acc: 0.9399 - val_loss: 0.6903 - val_acc: 0.8905\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.88876 to 0.89053, saving model to models/bottleneck_features.h5\n",
      "Epoch 14/100\n",
      " - 5s - loss: 0.2346 - acc: 0.9369 - val_loss: 0.6680 - val_acc: 0.8935\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.89053 to 0.89349, saving model to models/bottleneck_features.h5\n",
      "Epoch 15/100\n",
      " - 5s - loss: 0.2014 - acc: 0.9477 - val_loss: 0.5846 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.89349 to 0.90296, saving model to models/bottleneck_features.h5\n",
      "Epoch 16/100\n",
      " - 5s - loss: 0.2079 - acc: 0.9493 - val_loss: 0.8706 - val_acc: 0.8822\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.90296\n",
      "Epoch 17/100\n",
      " - 5s - loss: 0.1916 - acc: 0.9517 - val_loss: 0.7434 - val_acc: 0.8964\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.90296\n",
      "Epoch 18/100\n",
      " - 5s - loss: 0.1673 - acc: 0.9566 - val_loss: 0.6895 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.90296 to 0.90533, saving model to models/bottleneck_features.h5\n",
      "Epoch 19/100\n",
      " - 5s - loss: 0.1768 - acc: 0.9572 - val_loss: 0.7924 - val_acc: 0.8834\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.90533\n",
      "Epoch 20/100\n",
      " - 5s - loss: 0.1846 - acc: 0.9585 - val_loss: 0.7927 - val_acc: 0.8893\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.90533\n",
      "Epoch 21/100\n",
      " - 5s - loss: 0.1409 - acc: 0.9650 - val_loss: 0.9180 - val_acc: 0.8911\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.90533\n",
      "Epoch 22/100\n",
      " - 5s - loss: 0.1632 - acc: 0.9627 - val_loss: 0.7732 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.90533\n",
      "Epoch 23/100\n",
      " - 5s - loss: 0.1557 - acc: 0.9648 - val_loss: 0.7824 - val_acc: 0.8935\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.90533\n",
      "Epoch 00023: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Model saving callback\n",
    "# checkpointer = ModelCheckpoint(filepath='models/data_augmentation.h5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "checkpointer = ModelCheckpoint(filepath='models/bottleneck_features.h5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', verbose=1, patience=5)\n",
    "\n",
    "# history = model.fit_generator(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=train_samples // batch_size,\n",
    "#         epochs=epochs,\n",
    "#         callbacks=[checkpointer, early_stopping],\n",
    "#         verbose=2,\n",
    "#         validation_data=valid_generator,\n",
    "#         validation_steps=validation_samples // batch_size,)\n",
    "\n",
    "history = model_top.fit(\n",
    "        train_data,\n",
    "        train_labels,\n",
    "        verbose=2,\n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        callbacks=[checkpointer, early_stopping],\n",
    "        validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690/1690 [==============================] - 0s 152us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7823642365647788, 0.8934911239782029]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.evaluate_generator(validation_generator, validation_samples)\n",
    "model_top.evaluate(validation_data, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "#fig.savefig('../images/data_augmentation.svg', format='svg', dpi=1200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
