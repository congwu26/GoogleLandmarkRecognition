{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from skimage.feature import plot_matches\n",
    "from skimage.measure import ransac\n",
    "from skimage.transform import AffineTransform\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.python.platform import app\n",
    "from delf import feature_io\n",
    "\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_path='./delf-train/'\n",
    "dev_path='./delf-dev/'\n",
    "test_path='./delf-test/'\n",
    "non_landmark_dev_path='./delf-nlm-dev/'\n",
    "\n",
    "_DISTANCE_THRESHOLD = 0.8\n",
    "\n",
    "input_shape=(384,384)\n",
    "\n",
    "n_cat=14942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_info=pd.read_csv('train_info_red_sample_1.csv', index_col='id')\n",
    "train_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#train_image_files=glob.glob(train_path+'*.jpg')\n",
    "#train_image_ids=[image_file.replace(\n",
    "#    '.jpg','').replace(train_path,'') for image_file in train_image_files]\n",
    "train_info_full=pd.read_csv('train.csv', index_col='id')\n",
    "#train_info_full.head()\n",
    "#train_info=train_info_full.loc[train_image_ids]\n",
    "#train_info['filename']=pd.Series(train_image_files, index=train_image_ids)\n",
    "\n",
    "#train_info_correct=pd.read_csv('train_info_correct.csv', index_col='id')\n",
    "#train_info=train_info[train_info['landmark_id'].isin(train_info_correct['landmark_id'])]\n",
    "\n",
    "#train_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_cat_train=train_info['landmark_id'].nunique()\n",
    "print(n_cat_train)\n",
    "if n_cat_train != n_cat:\n",
    "    warnings.warn('Warning: The training data is not compatible.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dev_image_files=glob.glob(dev_path+'*_loc.npy')\n",
    "dev_image_ids=[image_file.replace(\n",
    "    '_loc.npy','').replace(dev_path,'') for image_file in dev_image_files]\n",
    "dev_info=train_info_full.loc[dev_image_ids]\n",
    "dev_info['filename']=pd.Series(dev_image_files, index=dev_image_ids)\n",
    "#dev_info=dev_info[dev_info['landmark_id'].isin(train_info['landmark_id'])]\n",
    "dev_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "non_landmark_dev_image_files=glob.glob(non_landmark_dev_path+'*_loc.npy')\n",
    "nlm_dev_df=pd.DataFrame({'filename':non_landmark_dev_image_files})\n",
    "nlm_dev_df['landmark_id']=-1\n",
    "nlm_dev_df.index=[str(i) for i in nlm_dev_df.index]\n",
    "print(len(nlm_dev_df))\n",
    "nlm_dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_info_full=pd.read_csv('test.csv', index_col='id')\n",
    "test_info_full.head()\n",
    "\n",
    "test_image_files=glob.glob(test_path+'*_loc.npy')\n",
    "test_image_ids=[image_file.replace(\n",
    "    '_loc.npy','').replace(test_path,'') for image_file in test_image_files]\n",
    "\n",
    "test_info=test_info_full.loc[test_image_ids]\n",
    "test_info['filename']=pd.Series(test_image_files, index=test_image_ids)\n",
    "\n",
    "test_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#candidates=pd.read_csv('dd_2nd_choice_preds.csv', sep=',| ', engine='python')\n",
    "#candidates.columns=['pred_id', 'nn_conf']\n",
    "#candidates=candidates[candidates.index.isin(test_info.index)]\n",
    "#print(len(candidates))\n",
    "#candidates.to_csv('delf-scored-candidates.csv')\n",
    "#candidates.to_csv('delf-scored-candidates-p2.csv')\n",
    "#candidates.to_csv('delf-scored-candidates-p3.csv')\n",
    "#candidates.to_csv('delf-scored-candidates-p4.csv')\n",
    "\n",
    "candidates=pd.read_csv('delf-scored-candidates.csv', index_col=0)\n",
    "candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_delf_features(img_id, ddir):\n",
    "    locations=np.load(ddir+img_id+'_loc.npy')\n",
    "    descriptions=np.load(ddir+img_id+'_desc.npy')\n",
    "    return locations, descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a1,b1=load_delf_features(dev_info.index[1], 'delf-dev/')\n",
    "a2,b2=load_delf_features(dev_info.index[2], 'delf-dev/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compare_imgs_1_preloaded(locations_1, descriptors_1, d1_tree, img_id_2, dir_2='delf-train/'):\n",
    "    # Read features.\n",
    "#    locations_1, descriptors_1 = load_delf_features(img_id_1, dir_1)\n",
    "    num_features_1 = locations_1.shape[0]\n",
    "    #print(\"Loaded image 1's %d features\" % num_features_1)\n",
    "    locations_2, descriptors_2 = load_delf_features(img_id_2, dir_2)\n",
    "    num_features_2 = locations_2.shape[0]\n",
    "    #print(\"Loaded image 2's %d features\" % num_features_2)\n",
    "\n",
    "    if len(locations_1)*len(locations_2)==0:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    _, indices = d1_tree.query(\n",
    "      descriptors_2, distance_upper_bound=_DISTANCE_THRESHOLD)\n",
    "\n",
    "    if len(indices)==0:\n",
    "        return 0\n",
    "    \n",
    "    # Select feature locations for putative matches.       \n",
    "    \n",
    "    locations_2_to_use = np.array([\n",
    "      locations_2[i,]\n",
    "      for i in range(num_features_2)\n",
    "      if indices[i] != num_features_1\n",
    "    ])\n",
    "    locations_1_to_use = np.array([\n",
    "      locations_1[indices[i],]\n",
    "      for i in range(num_features_2)\n",
    "      if indices[i] != num_features_1\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Perform geometric verification using RANSAC.                                                   \n",
    "\n",
    "    \n",
    "    if len(locations_1_to_use)*len(locations_2_to_use)==0:\n",
    "        return 0\n",
    "\n",
    "    _, inliers = ransac(\n",
    "      (locations_1_to_use, locations_2_to_use),\n",
    "      AffineTransform,\n",
    "      min_samples=3,\n",
    "      residual_threshold=20,\n",
    "      max_trials=1000)\n",
    "\n",
    "    if inliers is None:\n",
    "        score=0.\n",
    "    else:\n",
    "        score=sum(inliers)\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compare_imgs(img_id_1, img_id_2, dir_1, dir_2='delf-train/', plot=False, img_dir_1=None, img_dir_2=None):\n",
    "    # Read features.\n",
    "    locations_1, descriptors_1 = load_delf_features(img_id_1, dir_1)\n",
    "    num_features_1 = locations_1.shape[0]\n",
    "    #print(\"Loaded image 1's %d features\" % num_features_1)\n",
    "    locations_2, descriptors_2 = load_delf_features(img_id_2, dir_2)\n",
    "    num_features_2 = locations_2.shape[0]\n",
    "    #print(\"Loaded image 2's %d features\" % num_features_2)\n",
    "\n",
    "    if len(locations_1)*len(locations_2)==0:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    d1_tree = cKDTree(descriptors_1)\n",
    "    _, indices = d1_tree.query(\n",
    "      descriptors_2, distance_upper_bound=_DISTANCE_THRESHOLD)\n",
    "\n",
    "    # Select feature locations for putative matches.       \n",
    "    \n",
    "    locations_2_to_use = np.array([\n",
    "      locations_2[i,]\n",
    "      for i in range(num_features_2)\n",
    "      if indices[i] != num_features_1\n",
    "    ])\n",
    "    locations_1_to_use = np.array([\n",
    "      locations_1[indices[i],]\n",
    "      for i in range(num_features_2)\n",
    "      if indices[i] != num_features_1\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Perform geometric verification using RANSAC.                                                   \n",
    "\n",
    "    if len(locations_1_to_use)*len(locations_2_to_use)==0:\n",
    "        score=0\n",
    "    else:\n",
    "        _, inliers = ransac(\n",
    "          (locations_1_to_use, locations_2_to_use),\n",
    "          AffineTransform,\n",
    "          min_samples=3,\n",
    "          residual_threshold=20,\n",
    "          max_trials=1000)\n",
    "\n",
    "        if inliers is None:\n",
    "            score=0.\n",
    "        else:\n",
    "            score=sum(inliers)\n",
    "    \n",
    "    if plot:\n",
    "        _, ax = plt.subplots()\n",
    "        img_1=cv2.cvtColor(\n",
    "                    cv2.resize(cv2.imread(img_dir_1+img_id_1+'.jpg'),input_shape),\n",
    "                    cv2.COLOR_BGR2RGB)/255.\n",
    "        img_2=cv2.cvtColor(\n",
    "                    cv2.resize(cv2.imread(img_dir_2+img_id_2+'.jpg'),input_shape),\n",
    "                    cv2.COLOR_BGR2RGB)/255. \n",
    "        \n",
    "        inlier_idxs = np.nonzero(inliers)[0]\n",
    "        plot_matches(\n",
    "          ax,\n",
    "          img_1,\n",
    "          img_2,\n",
    "          locations_1_to_use,\n",
    "          locations_2_to_use,\n",
    "          np.column_stack((inlier_idxs, inlier_idxs)),\n",
    "          matches_color='b')\n",
    "        ax.axis('off')\n",
    "        ax.set_title('DELF correspondences')\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compare_features(locations_1, descriptors_1, locations_2, descriptors_2, d1_tree):\n",
    "\n",
    "    num_features_1 = locations_1.shape[0]\n",
    "    num_features_2 = locations_2.shape[0]\n",
    "    \n",
    "    if num_features_1*num_features_2==0:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "#    d1_tree = cKDTree(descriptors_1)\n",
    "    _, indices = d1_tree.query(\n",
    "      descriptors_2, distance_upper_bound=_DISTANCE_THRESHOLD)\n",
    "\n",
    "#    print(indices)\n",
    "    if len(indices)==0:\n",
    "        return 0\n",
    "    # Select feature locations for putative matches.       \n",
    "    \n",
    "    locations_2_to_use = np.array([\n",
    "      locations_2[i,]\n",
    "      for i in range(num_features_2)\n",
    "      if indices[i] != num_features_1\n",
    "    ])\n",
    "    locations_1_to_use = np.array([\n",
    "      locations_1[indices[i],]\n",
    "      for i in range(num_features_2)\n",
    "      if indices[i] != num_features_1\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Perform geometric verification using RANSAC.                                                   \n",
    "\n",
    "\n",
    "    if len(locations_1_to_use)*len(locations_2_to_use)==0:\n",
    "        return 0\n",
    "    \n",
    "    _, inliers = ransac(\n",
    "      (locations_1_to_use, locations_2_to_use),\n",
    "      AffineTransform,\n",
    "      min_samples=3,\n",
    "      residual_threshold=20,\n",
    "      max_trials=1000)\n",
    "\n",
    "    if inliers is None:\n",
    "        score=0.\n",
    "    else:\n",
    "        score=sum(inliers)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "score=compare_imgs(train_info[train_info['landmark_id']==6933].sample(1).index[0],\n",
    "                   train_info[train_info['landmark_id']==6933].sample(1).index[0], \n",
    "                   dir_1='delf-train/', dir_2='delf-train/', plot=True,\n",
    "                  img_dir_1='train-highres/', img_dir_2='train-highres/')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def verify_hypothesis(pred_info, ref_info, pred_path, ref_path, n_imgs=8, i_start=0, io_n=100, checkpoint_n=100):\n",
    "    for i,img_id in enumerate(pred_info.index):\n",
    "        if i < i_start:\n",
    "            continue\n",
    "        hyp_id=pred_info.loc[img_id]['pred_id']\n",
    "        n_ref_imgs=sum(ref_info['landmark_id']==hyp_id)\n",
    "        ref_img_ids=ref_info[ref_info['landmark_id']==hyp_id].sample(\n",
    "            min(n_imgs,n_ref_imgs)).index\n",
    "        \n",
    "        try:\n",
    "            locations_1, descriptors_1 = load_delf_features(img_id, pred_path)\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            print('Error: could not read id:', img_id, '-> Set scores to zero.')\n",
    "            pred_info.loc[img_id, 'delf_max_score']=0\n",
    "            pred_info.loc[img_id, 'delf_mean_score']=0\n",
    "            pred_info.loc[img_id, 'delf_m2_score']=0\n",
    "            continue\n",
    "        \n",
    "        d1_tree = cKDTree(descriptors_1)\n",
    "        scores=np.zeros(len(ref_img_ids))\n",
    "    \n",
    "        for j,ref_img_id in enumerate(ref_img_ids):\n",
    "            try:\n",
    "                scores[j]=compare_imgs_1_preloaded(locations_1, descriptors_1, \n",
    "                                                   d1_tree, ref_img_id, ref_path)\n",
    "            except KeyboardInterrupt:\n",
    "                raise\n",
    "            except:\n",
    "                print('An error has occured. Set score to zero.')\n",
    "        max_score=np.max(scores)\n",
    "        mean_score=np.mean(scores)\n",
    "        m2_score=np.mean(np.sort(scores)[-n_imgs//2:])\n",
    "\n",
    "        pred_info.loc[img_id, 'delf_max_score']=max_score\n",
    "        pred_info.loc[img_id, 'delf_mean_score']=mean_score\n",
    "        pred_info.loc[img_id, 'delf_m2_score']=m2_score\n",
    "\n",
    "        if i % io_n==0:\n",
    "            print(i,'/',len(pred_info), ' -->', hyp_id, max_score, mean_score, m2_score)\n",
    "        if i % checkpoint_n==0 and i > 0:\n",
    "            print('Checkpoint ...')\n",
    "            pred_info.to_csv('verify-chp-1.csv')\n",
    "            pred_info.to_csv('verify-chp-2.csv')\n",
    "            pred_info.to_csv('verify-chp-3.csv')\n",
    "            np.savetxt('delf-predict-last-i.txt', np.array([i]))\n",
    "            \n",
    "    return pred_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "verify_hypothesis(candidates, train_info, test_path, train_path, n_imgs=32, io_n=20, checkpoint_n=200, i_start=22000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "candidates.to_csv('delf-scored-candidates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
